{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 说明\n",
    "本次作业为二种类型，分别是选择题和实践题。其中选择题是不定项选择。实践题需要在提示的地方填上代码，跑通项目。\n",
    "\n",
    "## 资料\n",
    "做作业时可以参考以下资料。\n",
    "\n",
    "PaddleSlim代码地址： [https://github.com/PaddlePaddle/PaddleSlim](https://github.com/PaddlePaddle/PaddleSlim)\n",
    "\n",
    "文档地址：[https://paddlepaddle.github.io/PaddleSlim/](https://paddlepaddle.github.io/PaddleSlim/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 选择题\n",
    "【1】定点化量化的优点有哪些？\n",
    "\n",
    "A. 存带宽  B. 低功耗  C. 低计算资源  D. 低存储体积\n",
    "\n",
    "【2】在常规蒸馏任务中，以下说法正确的是：\n",
    "\n",
    "A. 只有teacher model的参数需要更新\n",
    "\n",
    "B. 只有student model的参数需要更新\n",
    "\n",
    "C. teacher model和student model 的参数都需要更新\n",
    "\n",
    "D.teacher model和student model 的参数都不需要更新\n",
    "\n",
    "\n",
    "【3】是否能用MobileNetv1蒸馏ResNet50？\n",
    "\n",
    "A: 能\n",
    "\n",
    "B: 不能\n",
    "\n",
    "【4】下面方法哪些可以减少模型推理时间？\n",
    "\n",
    "A. 只对权重weight进行量化\n",
    "\n",
    "B. 对ResNet50模型进行蒸馏提高精度\n",
    "\n",
    "C. 对模型进行裁剪，减少通道数\n",
    "\n",
    "D. 对权重weight和激活进行量化，预测采用INT8计算\n",
    "\n",
    "\n",
    "【5】NAS的三个关键要素是：\n",
    "\n",
    "A. 搜索空间\n",
    "\n",
    "B. 搜索算法\n",
    "\n",
    "C. 模型优化\n",
    "\n",
    "D. 模型评估\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 选择题答题卡\n",
    "\n",
    "请将每道选择题的答案写在这里：\n",
    "\n",
    "【1】ABCD\n",
    "\n",
    "【2】B\n",
    "\n",
    "【3】B\n",
    "\n",
    "【4】BCD\n",
    "\n",
    "【5】ABD\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#  图像分类模型量化教程\n",
    "\n",
    "该教程以图像分类模型MobileNetV1为例，说明如何快速使用[量化训练接口](https://paddlepaddle.github.io/PaddleSlim/api_cn/quantization_api.html#quant-aware)。\n",
    "该示例包含以下步骤：\n",
    "\n",
    "1. 导入依赖\n",
    "2. 构建模型\n",
    "3. 定义输入数据\n",
    "4. 训练模型\n",
    "5. 量化模型 ``这个步骤中需要添加代码``\n",
    "6. 训练和测试量化后的模型\n",
    "\n",
    "以下章节依次介绍每个步骤的内容。\n",
    "\n",
    "## 0. 安装paddleslim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\u001b[0m\n",
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
      "Collecting paddleslim\n",
      "\u001b[?25l  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/69/3c/880afac020e3393da5a55b4e0b504d2b644a7ebe91092d953185f09660d1/paddleslim-1.0.1-py2.py3-none-any.whl (103kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 4.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages (from paddleslim) (4.36.1)\n",
      "Installing collected packages: paddleslim\n",
      "Successfully installed paddleslim-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install paddleslim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. 导入依赖\n",
    "\n",
    "PaddleSlim依赖Paddle1.7版本，请确认已正确安装Paddle，然后按以下方式导入Paddle和PaddleSlim:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import paddleslim as slim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "## 2. 构建模型\n",
    "\n",
    "该章节构造一个用于对MNIST数据进行分类的分类模型，选用`MobileNetV1`，并将输入大小设置为`[1, 28, 28]`，输出类别数为10。\n",
    "为了方便展示示例，我们在`paddleslim.models`下预定义了用于构建分类模型的方法，执行以下代码构建分类模型：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "use_gpu = fluid.is_compiled_with_cuda()\n",
    "exe, train_program, val_program, inputs, outputs = slim.models.image_classification(\"MobileNet\", [1, 28, 28], 10, use_gpu=use_gpu)\n",
    "place = fluid.CUDAPlace(0) if fluid.is_compiled_with_cuda() else fluid.CPUPlace()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n",
    "## 3 定义输入数据\n",
    "\n",
    "为了快速执行该示例，我们选取简单的MNIST数据，Paddle框架的`paddle.dataset.mnist`包定义了MNIST数据的下载和读取。\n",
    "代码如下：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import paddle.dataset.mnist as reader\n",
    "train_reader = paddle.batch(\n",
    "        reader.train(), batch_size=128, drop_last=True)\n",
    "test_reader = paddle.batch(\n",
    "        reader.test(), batch_size=128, drop_last=True)\n",
    "data_feeder = fluid.DataFeeder(inputs, place)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n",
    "## 4. 训练和测试\n",
    "\n",
    "先定义训练和测试函数，正常训练和量化训练时只需要调用函数即可。在训练函数中执行了一个epoch的训练，因为MNIST数据集数据较少，一个epoch就可将top1精度训练到95%以上。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(prog):\n",
    "    iter = 0\n",
    "    for data in train_reader():\n",
    "        acc1, acc5, loss = exe.run(prog, feed=data_feeder.feed(data), fetch_list=outputs)\n",
    "        if iter % 100 == 0:\n",
    "            print('train iter={}, top1={}, top5={}, loss={}'.format(iter, acc1.mean(), acc5.mean(), loss.mean()))\n",
    "        iter += 1\n",
    "        \n",
    "def test(prog):\n",
    "    iter = 0\n",
    "    res = [[], []]\n",
    "    for data in test_reader():\n",
    "        acc1, acc5, loss = exe.run(prog, feed=data_feeder.feed(data), fetch_list=outputs)\n",
    "        if iter % 100 == 0:\n",
    "            print('test iter={}, top1={}, top5={}, loss={}'.format(iter, acc1.mean(), acc5.mean(), loss.mean()))\n",
    "        res[0].append(acc1.mean())\n",
    "        res[1].append(acc5.mean())\n",
    "        iter += 1\n",
    "    print('final test result top1={}, top5={}'.format(np.array(res[0]).mean(), np.array(res[1]).mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "调用train函数训练分类网络，train_program是在第2步：构建网络中定义的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train iter=0, top1=0.09375, top5=0.5625, loss=2.67902231216\n",
      "train iter=100, top1=0.9140625, top5=1.0, loss=0.210934847593\n",
      "train iter=200, top1=0.9140625, top5=1.0, loss=0.261303722858\n",
      "train iter=300, top1=0.9609375, top5=0.984375, loss=0.188525319099\n",
      "train iter=400, top1=0.9375, top5=1.0, loss=0.177733242512\n"
     ]
    }
   ],
   "source": [
    "train(train_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "调用test函数测试分类网络，val_program是在第2步：构建网络中定义的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test iter=0, top1=0.9921875, top5=1.0, loss=0.0384036004543\n",
      "final test result top1=0.965144217014, top5=0.999499201775\n"
     ]
    }
   ],
   "source": [
    "test(val_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n",
    "## 5. 量化模型\n",
    "\n",
    "按照配置在train_program和val_program中加入量化和反量化op.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TENSORRT_OP_TYPES = [\r\n",
    "    'mul', 'conv2d', 'pool2d', 'depthwise_conv2d', 'elementwise_add',\r\n",
    "    'leaky_relu'\r\n",
    "]\r\n",
    "TRANSFORM_PASS_OP_TYPES = ['conv2d', 'depthwise_conv2d', 'mul']\r\n",
    "\r\n",
    "QUANT_DEQUANT_PASS_OP_TYPES = [\r\n",
    "        \"pool2d\", \"elementwise_add\", \"concat\", \"softmax\", \"argmax\", \"transpose\",\r\n",
    "        \"equal\", \"gather\", \"greater_equal\", \"greater_than\", \"less_equal\",\r\n",
    "        \"less_than\", \"mean\", \"not_equal\", \"reshape\", \"reshape2\",\r\n",
    "        \"bilinear_interp\", \"nearest_interp\", \"trilinear_interp\", \"slice\",\r\n",
    "        \"squeeze\", \"elementwise_sub\", \"relu\", \"relu6\", \"leaky_relu\", \"tanh\", \"swish\"\r\n",
    "    ]\r\n",
    "\r\n",
    "_quant_config_default = {\r\n",
    "    # weight quantize type, default is 'channel_wise_abs_max'\r\n",
    "    'weight_quantize_type': 'channel_wise_abs_max',\r\n",
    "    # activation quantize type, default is 'moving_average_abs_max'\r\n",
    "    'activation_quantize_type': 'moving_average_abs_max',\r\n",
    "    # weight quantize bit num, default is 8\r\n",
    "    'weight_bits': 8,\r\n",
    "    # activation quantize bit num, default is 8\r\n",
    "    'activation_bits': 8,\r\n",
    "    # ops of name_scope in not_quant_pattern list, will not be quantized\r\n",
    "    'not_quant_pattern': ['skip_quant'],\r\n",
    "    # ops of type in quantize_op_types, will be quantized\r\n",
    "    'quantize_op_types': ['conv2d', 'depthwise_conv2d', 'mul'],\r\n",
    "    # data type after quantization, such as 'uint8', 'int8', etc. default is 'int8'\r\n",
    "    'dtype': 'int8',\r\n",
    "    # window size for 'range_abs_max' quantization. defaulf is 10000\r\n",
    "    'window_size': 10000,\r\n",
    "    # The decay coefficient of moving average, default is 0.9\r\n",
    "    'moving_rate': 0.9,\r\n",
    "    # if True, 'quantize_op_types' will be TENSORRT_OP_TYPES\r\n",
    "    'for_tensorrt': False,\r\n",
    "    # if True, 'quantoze_op_types' will be TRANSFORM_PASS_OP_TYPES + QUANT_DEQUANT_PASS_OP_TYPES\r\n",
    "    'is_full_quantize': False\r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-06 13:05:32,600-INFO: quant_aware config {'weight_bits': 8, 'weight_quantize_type': 'channel_wise_abs_max', 'is_full_quantize': False, 'dtype': 'int8', 'moving_rate': 0.9, 'window_size': 10000, 'activation_bits': 8, 'quantize_op_types': ['conv2d', 'depthwise_conv2d', 'mul'], 'not_quant_pattern': ['skip_quant'], 'activation_quantize_type': 'moving_average_abs_max', 'for_tensorrt': False}\n",
      "2020-04-06 13:05:33,643-INFO: quant_aware config {'weight_bits': 8, 'weight_quantize_type': 'channel_wise_abs_max', 'is_full_quantize': False, 'dtype': 'int8', 'moving_rate': 0.9, 'window_size': 10000, 'activation_bits': 8, 'quantize_op_types': ['conv2d', 'depthwise_conv2d', 'mul'], 'not_quant_pattern': ['skip_quant'], 'activation_quantize_type': 'moving_average_abs_max', 'for_tensorrt': False}\n"
     ]
    }
   ],
   "source": [
    "place = exe.place\n",
    "quant_program = slim.quant.quant_aware(train_program, place, config=_quant_config_default, scope=None, for_test=False)        #请在次数添加你的代码\n",
    "val_quant_program = slim.quant.quant_aware(val_program, place, config=_quant_config_default, scope=None, for_test=False)    #请在次数添加你的代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 6 训练和测试量化后的模型¶\n",
    "微调量化后的模型，训练一个epoch后测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train iter=0, top1=0.9453125, top5=0.9921875, loss=0.270684301853\n",
      "train iter=100, top1=0.9609375, top5=1.0, loss=0.099116653204\n",
      "train iter=200, top1=0.984375, top5=1.0, loss=0.0825728997588\n",
      "train iter=300, top1=0.984375, top5=0.9921875, loss=0.0900387614965\n",
      "train iter=400, top1=0.9453125, top5=1.0, loss=0.142843589187\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train(quant_program)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "测试量化后的模型，和3.2 训练和测试中得到的测试结果相比，精度相近，达到了无损量化。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test iter=0, top1=0.9453125, top5=1.0, loss=0.15757009387\n",
      "final test result top1=0.975560903549, top5=0.999699532986\n"
     ]
    }
   ],
   "source": [
    "test(val_quant_program)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.7.0 (Python 2.7)",
   "language": "python",
   "name": "py27-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
