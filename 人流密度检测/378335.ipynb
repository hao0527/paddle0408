{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 试题说明\n",
    "近年来，应用于监控场景的行人分析视觉技术日益受到广泛关注。包括人体检测、人体属性识别、人流密度估计等技术在内的多种视觉技术，已获得在居家、安防、新零售等多个重要领域的广泛应用。其中作用于人流密集场景的人流密度估计技术（crowd density estimation）因其远高于肉眼计数的准确率和速度，已广泛应用于机场、车站、运营车辆、艺术展馆等多种场景，一方面可有效防止拥挤踩踏、超载等隐患发生，另一方面还可帮助零售商等统计客流。本试题以人流密度估计作为内容，答题者需要以对应主题作为技术核心，开发出能适用于密集、稀疏、高空、车载等多种复杂场景的通用人流密度估计算法，准确估计出输入图像中的总人数。\n",
    "\n",
    "### 任务描述\n",
    "要求参赛者给出一个算法或模型，对于给定的图片，统计图片中的总人数。给定图片数据，选手据此训练模型，为每张测试数据预测出最准确的人数。\n",
    "\n",
    "### 数据说明\n",
    "本竞赛所用训练和测试图片均来自一般监控场景，但包括多种视角（如低空、高空、鱼眼等），图中行人的相对尺寸也会有较大差异。部分训练数据参考了公开数据集（如ShanghaiTech [1], UCF-CC-50 [2], WorldExpo’10 [3]，Mall [4] 等）。\n",
    "\n",
    "本竞赛的数据标注均在对应json文件中，每张训练图片的标注为以下两种方式之一：\n",
    "\n",
    "（1）部分数据对图中行人提供了方框标注（boundingbox），格式为[x, y, w, h][x,y,w,h]；\n",
    "\n",
    "（2）部分图对图中行人提供了头部的打点标注，坐标格式为[x, y][x,y]。\n",
    "\n",
    "此外部分图片还提供了忽略区（ignore_region）标注，格式为[x_0, y_0, x_1, y_1, …, x_n, y_n]组成的多边形（注意一张图片可能有多个多边形忽略区），图片在忽略区内的部分不参与训练/测试。\n",
    "\n",
    "### 提交答案\n",
    "考试提交，需要提交**模型代码项目版本**和**结果文件**。结果文件为CSV文件格式，可以自定义文件名称，文件内的字段需要按照指定格式写入，其中，id表示图片文件名，predicted表示图片中行人个数。\n",
    "\n",
    "结果文件，内容应参考如下：\n",
    "\n",
    "\n",
    "| id           | predicted|\n",
    "| --------     | -------- |\n",
    "| 1            | 23   | \n",
    "| 2            | 50   | \n",
    "| 图片文件名     |图片中行人个数   | \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !unzip -q -o data/data1917/train_new.zip\r\n",
    "# !unzip -q -o data/data1917/test_new.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import zipfile\r\n",
    "import paddle\r\n",
    "import paddle.fluid as fluid\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib.image as mping\r\n",
    "\r\n",
    "import json\r\n",
    "import numpy as np\r\n",
    "import cv2\r\n",
    "import sys\r\n",
    "import time\r\n",
    "import h5py\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "from scipy.ndimage.filters import gaussian_filter \r\n",
    "import scipy\r\n",
    "from matplotlib import cm as CM\r\n",
    "from paddle.utils.plot import Ploter\r\n",
    "from PIL import Image\r\n",
    "from PIL import ImageFile\r\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "'''\r\n",
    "查看train.json相关信息，重点关注annotations中的标注信息\r\n",
    "'''\r\n",
    "with open('/home/aistudio/data/data1917/train.json',encoding='utf-8') as f:\r\n",
    "    content = json.load(f)\r\n",
    "\r\n",
    "'''\r\n",
    "将上面的到的content中的name中的“stage1/”去掉\r\n",
    "'''\r\n",
    "for j in range(len(content['annotations'])):\r\n",
    "    content['annotations'][j]['name'] = content['annotations'][j]['name'].lstrip('stage1').lstrip('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\r\n",
    "使用高斯滤波变换生成密度图\r\n",
    "'''\r\n",
    "def gaussian_filter_density(gt):\r\n",
    "   \r\n",
    "    # 初始化密度图\r\n",
    "    density = np.zeros(gt.shape, dtype=np.float32)\r\n",
    "    \r\n",
    "    # 获取gt中不为0的元素的个数\r\n",
    "    gt_count = np.count_nonzero(gt)\r\n",
    "    \r\n",
    "    # 如果gt全为0，就返回全0的密度图\r\n",
    "    if gt_count == 0:\r\n",
    "        return density\r\n",
    "    \r\n",
    "    pts = np.array(list(zip(np.nonzero(gt)[1].ravel(), np.nonzero(gt)[0].ravel())))\r\n",
    "    \r\n",
    "\r\n",
    "    for i, pt in enumerate(pts):\r\n",
    "        pt2d = np.zeros(gt.shape, dtype=np.float32)\r\n",
    "        pt2d[pt[1],pt[0]] = 1.\r\n",
    "        if gt_count > 1:\r\n",
    "            # sigma = (distances[i][1]+distances[i][2]+distances[i][3])*0.1\r\n",
    "            sigma = 25\r\n",
    "        else:\r\n",
    "            sigma = np.average(np.array(gt.shape))/2./2. \r\n",
    "        \r\n",
    "        density += scipy.ndimage.filters.gaussian_filter(pt2d, sigma, mode='constant')\r\n",
    "\r\n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\r\n",
    "图片操作：对图片进行resize、归一化，将方框标注变为点标注\r\n",
    "返回：resize后的图片 和 gt  [(x1,y1),(x2,y2),...]\r\n",
    "'''\r\n",
    "def picture_opt(img,ann):\r\n",
    "    size_x,size_y = img.size\r\n",
    "    train_img_size = (640,480)\r\n",
    "    img = img.resize(train_img_size,Image.ANTIALIAS)\r\n",
    "    img = np.array(img)                  \r\n",
    "    img = img / 255.0\r\n",
    "\r\n",
    "    gt = []\r\n",
    "    for b_l in range(len(ann)):\r\n",
    "        # 假设人体是使用方框标注的，通过求均值的方法将框变为点\r\n",
    "        if 'w' in ann[b_l].keys(): #if True 是框框\r\n",
    "            x = (ann[b_l]['x']+(ann[b_l]['x']+ann[b_l]['w']))/2\r\n",
    "            y = ann[b_l]['y']+20\r\n",
    "            x = (x*640/size_x)/8\r\n",
    "            y = (y*480/size_y)/8\r\n",
    "            gt.append((x,y))   \r\n",
    "        else:\r\n",
    "            x = ann[b_l]['x']\r\n",
    "            y = ann[b_l]['y']\r\n",
    "            x = (x*640/size_x)/8\r\n",
    "            y = (y*480/size_y)/8\r\n",
    "            gt.append((x,y)) \r\n",
    "   \r\n",
    "    return img,gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\r\n",
    "密度图处理\r\n",
    "'''\r\n",
    "def ground(img,gt):\r\n",
    "    imgs = img\r\n",
    "    x = imgs.shape[0]/8\r\n",
    "    y = imgs.shape[1]/8\r\n",
    "    k = np.zeros((int(x),int(y)))\r\n",
    "\r\n",
    "    for i in range(0,len(gt)):\r\n",
    "        if int(gt[i][1]) < int(x) and int(gt[i][0]) < int(y):\r\n",
    "            k[int(gt[i][1]),int(gt[i][0])]=1\r\n",
    "\r\n",
    "    k = gaussian_filter_density(k)\r\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\r\n",
    "定义数据生成器\r\n",
    "'''\r\n",
    "def train_set():\r\n",
    "    def inner():\r\n",
    "        for ig_index in range(2000):                                                 #遍历所有图片\r\n",
    "            if len(content['annotations'][ig_index]['annotation']) == 2:continue\r\n",
    "            if len(content['annotations'][ig_index]['annotation']) == 3:continue\r\n",
    "            if content['annotations'][ig_index]['ignore_region']:#if ignore_region 不为[]                #把忽略区域都用像素为0填上\r\n",
    "                ig_list = []                                                           #存放忽略区1的数据\r\n",
    "                ig_list1 = []                                                          #存放忽略区2的数据\r\n",
    "                # print(content['annotations'][ig_index]['ignore_region'])\r\n",
    "                if len(content['annotations'][ig_index]['ignore_region'])==1:           #因为每张图的忽略区域最多2个，这里是为1的情况\r\n",
    "                    # print('ig1',ig_index)\r\n",
    "                    ign_rge = content['annotations'][ig_index]['ignore_region'][0]       #取第一个忽略区的数据\r\n",
    "                    for ig_len in range(len(ign_rge)):                                   #遍历忽略区坐标个数，组成多少变型\r\n",
    "                        ig_list.append([ign_rge[ig_len]['x'],ign_rge[ig_len]['y']])       #取出每个坐标的x,y然后组成一个小列表放到ig_list\r\n",
    "                    ig_cv_img = cv2.imread(content['annotations'][ig_index]['name'])      #用cv2读取一张图片\r\n",
    "                    pts = np.array(ig_list,np.int32)                                      #把ig_list转成numpy.ndarray数据格式，为了填充需要\r\n",
    "                    cv2.fillPoly(ig_cv_img,[pts],(0,0,0),cv2.LINE_AA)                     #使用cv2.fillPoly方法对有忽略区的图片用像素为0填充\r\n",
    "                \r\n",
    "                    ig_img = Image.fromarray(cv2.cvtColor(ig_cv_img,cv2.COLOR_BGR2RGB))   #cv2转PIL\r\n",
    "                    \r\n",
    "                    ann = content['annotations'][ig_index]['annotation']          #把所有标注的信息读取出来\r\n",
    "                                                                  \r\n",
    "                    ig_im,gt = picture_opt(ig_img,ann)\r\n",
    "                    k = ground(ig_im,gt)\r\n",
    "                   \r\n",
    "                    groundtruth = np.asarray(k)\r\n",
    "                    groundtruth = groundtruth.T.astype('float32')\r\n",
    "                    ig_im = ig_im.transpose().astype('float32')\r\n",
    "                    yield ig_im,groundtruth\r\n",
    "                    \r\n",
    "                if len(content['annotations'][ig_index]['ignore_region'])==2:           #有2个忽略区域\r\n",
    "                    # print('ig2',ig_index)\r\n",
    "                    ign_rge = content['annotations'][ig_index]['ignore_region'][0]\r\n",
    "                    ign_rge1 = content['annotations'][ig_index]['ignore_region'][1]\r\n",
    "                    for ig_len in range(len(ign_rge)):\r\n",
    "                        ig_list.append([ign_rge[ig_len]['x'],ign_rge[ig_len]['y']])\r\n",
    "                    for ig_len1 in range(len(ign_rge1)):\r\n",
    "                        ig_list1.append([ign_rge1[ig_len1]['x'],ign_rge1[ig_len1]['y']])  \r\n",
    "                    ig_cv_img2 = cv2.imread(content['annotations'][ig_index]['name'])\r\n",
    "                    pts = np.array(ig_list,np.int32)\r\n",
    "                    pts1 = np.array(ig_list1,np.int32)\r\n",
    "                    cv2.fillPoly(ig_cv_img2,[pts],(0,0,0),cv2.LINE_AA)                \r\n",
    "                    cv2.fillPoly(ig_cv_img2,[pts1],(0,0,0),cv2.LINE_AA)\r\n",
    "                    \r\n",
    "                    ig_img2 = Image.fromarray(cv2.cvtColor(ig_cv_img2,cv2.COLOR_BGR2RGB))   #cv2转PIL\r\n",
    "                    \r\n",
    "                    ann = content['annotations'][ig_index]['annotation']                    #把所有标注的信息读取出来\r\n",
    "                                                                  \r\n",
    "                    ig_im,gt = picture_opt(ig_img2,ann)\r\n",
    "                    k = ground(ig_im,gt)\r\n",
    "                    k = np.zeros((int(ig_im.shape[0]/8),int(ig_im.shape[1]/8)))\r\n",
    "                    \r\n",
    "                    groundtruth = np.asarray(k)\r\n",
    "                    groundtruth = groundtruth.T.astype('float32')\r\n",
    "                    ig_im = ig_im.transpose().astype('float32')\r\n",
    "                    yield ig_im,groundtruth\r\n",
    "                    \r\n",
    "            else:\r\n",
    "                img = Image.open(content['annotations'][ig_index]['name'])\r\n",
    "                ann = content['annotations'][ig_index]['annotation']          #把所有标注的信息读取出来\r\n",
    "                \r\n",
    "                im,gt = picture_opt(img,ann)\r\n",
    "                k = ground(im,gt)\r\n",
    "                \r\n",
    "                groundtruth = np.asarray(k)\r\n",
    "                groundtruth = groundtruth.T.astype('float32')\r\n",
    "                im = im.transpose().astype('float32')\r\n",
    "                yield im,groundtruth\r\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE= 3    #每次取3张\r\n",
    "# 设置训练reader\r\n",
    "train_reader = paddle.batch(paddle.reader.shuffle(train_set(), buf_size=512),batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CNN(fluid.dygraph.Layer):\r\n",
    "    '''\r\n",
    "    网络\r\n",
    "    '''\r\n",
    "    def __init__(self):\r\n",
    "        super(CNN, self).__init__()\r\n",
    "\r\n",
    "        \r\n",
    "        self.conv01_1 = fluid.dygraph.Conv2D(num_channels=3, num_filters=64,filter_size=3,padding=1,act=\"relu\")\r\n",
    "        self.norm01 = fluid.dygraph.BatchNorm(num_channels=64, act='relu')\r\n",
    "        self.pool01=fluid.dygraph.Pool2D(pool_size=2,pool_type='max',pool_stride=2)\r\n",
    "        # self.dropout01 = fluid.layers.dropout(x=out,dropout_prob=0.25)\r\n",
    "\r\n",
    "        self.conv02_1 = fluid.dygraph.Conv2D(num_channels=64, num_filters=128,filter_size=3, padding=1,act=\"relu\")\r\n",
    "        self.norm02 = fluid.dygraph.BatchNorm(num_channels=128, act='relu')\r\n",
    "        self.pool02=fluid.dygraph.Pool2D(pool_size=2,pool_type='max',pool_stride=2)\r\n",
    "        # self.dropout02 = fluid.layers.dropout(x=out,dropout_prob=0.25)\r\n",
    "\r\n",
    "        self.conv03_1 = fluid.dygraph.Conv2D(num_channels=128, num_filters=256,filter_size=3, padding=1,act=\"relu\")\r\n",
    "        self.norm03 = fluid.dygraph.BatchNorm(num_channels=256, act='relu')\r\n",
    "        self.pool03=fluid.dygraph.Pool2D(pool_size=2,pool_type='max',pool_stride=2)\r\n",
    "        # self.dropout03 = fluid.layers.dropout(x=out,dropout_prob=0.25)\r\n",
    "\r\n",
    "        self.conv04_1 = fluid.dygraph.Conv2D(num_channels=256, num_filters=512,filter_size=3, padding=1,act=\"relu\")\r\n",
    "        self.norm04 = fluid.dygraph.BatchNorm(num_channels=512, act='relu')\r\n",
    "\r\n",
    "        self.conv05_1 = fluid.dygraph.Conv2D(num_channels=512, num_filters=512,filter_size=3,padding=1, act=\"relu\")\r\n",
    "        self.norm05 = fluid.dygraph.BatchNorm(num_channels=512, act='relu')\r\n",
    "\r\n",
    "        self.conv06 = fluid.dygraph.Conv2D(num_channels=512,num_filters=256,filter_size=3,padding=1,act='relu')\r\n",
    "        # self.dropout06 = fluid.layers.dropout(x=out,dropout_prob=0.5)\r\n",
    "\r\n",
    "        self.conv07 = fluid.dygraph.Conv2D(num_channels=256,num_filters=128,filter_size=3,padding=1,act='relu')\r\n",
    "        # self.dropout07 = fluid.layers.dropout(x=out,dropout_prob=0.5)\r\n",
    "\r\n",
    "        self.conv08 = fluid.dygraph.Conv2D(num_channels=128,num_filters=64,filter_size=3,padding=1,act='relu')\r\n",
    "        #self.norm08 = fluid.dygraph.BatchNorm(num_channels=64,act=None)\r\n",
    "        self.conv09 = fluid.dygraph.Conv2D(num_channels=64,num_filters=1,filter_size=1,padding=0,act=None)\r\n",
    "        \r\n",
    "\r\n",
    "    def forward(self, inputs, label=None):\r\n",
    "        \"\"\"前向计算\"\"\"\r\n",
    "        out = self.conv01_1(inputs)\r\n",
    "        out = self.norm01(out)\r\n",
    "        out = self.pool01(out)\r\n",
    "        out = fluid.layers.dropout(x=out, dropout_prob=0.25)\r\n",
    "        # out = self.dropout01(out)\r\n",
    "\r\n",
    "        out = self.conv02_1(out)\r\n",
    "        out = self.norm02(out)\r\n",
    "        out = self.pool02(out)\r\n",
    "        out = fluid.layers.dropout(x=out, dropout_prob=0.25)\r\n",
    "        # out = self.dropout02(out)\r\n",
    "\r\n",
    "        out = self.conv03_1(out)\r\n",
    "        out = self.norm03(out)\r\n",
    "        out = self.pool03(out)\r\n",
    "        out = fluid.layers.dropout(x=out, dropout_prob=0.25)\r\n",
    "        # out = self.dropout03(out)\r\n",
    "\r\n",
    "        out = self.conv04_1(out)    \r\n",
    "        out = self.norm04(out)\r\n",
    "        \r\n",
    "        out = self.conv05_1(out)\r\n",
    "        out = self.norm05(out)\r\n",
    "\r\n",
    "        out = self.conv06(out)\r\n",
    "        out = fluid.layers.dropout(x=out, dropout_prob=0.5)\r\n",
    "        # out = self.dropout06(out)\r\n",
    "        \r\n",
    "        out = self.conv07(out)\r\n",
    "        out = fluid.layers.dropout(x=out, dropout_prob=0.5)\r\n",
    "        # out = self.dropout07(out)\r\n",
    "\r\n",
    "        out = self.conv08(out)\r\n",
    "        # out = self.norm08(out)\r\n",
    "        out = self.conv09(out)\r\n",
    "        \r\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: [1.0431062e-06]\r"
     ]
    }
   ],
   "source": [
    "'''\r\n",
    "模型训练\r\n",
    "'''\r\n",
    "with fluid.dygraph.guard(place = fluid.CUDAPlace(0)):\r\n",
    "    cnn = CNN()\r\n",
    "    optimizer=fluid.optimizer.AdamOptimizer(learning_rate=0.001,parameter_list=cnn.parameters()) \r\n",
    "    for epoch_num in range(20):\r\n",
    "        for batch_id, data in enumerate(train_reader()):\r\n",
    "            dy_x_data = np.array([x[0] for x in data]).astype('float32')           \r\n",
    "            y_data = np.array([x[1] for x in data]).astype('float32') \r\n",
    "            y_data = y_data[:,np.newaxis] \r\n",
    "           \r\n",
    "            #将Numpy转换为DyGraph接收的输入\r\n",
    "            img = fluid.dygraph.to_variable(dy_x_data)\r\n",
    "            label = fluid.dygraph.to_variable(y_data)\r\n",
    "            label.stop_gradient = True\r\n",
    "\r\n",
    "            out = cnn(img,label)\r\n",
    "            loss = fluid.layers.square_error_cost(out, label)\r\n",
    "            avg_loss = fluid.layers.mean(loss)\r\n",
    "\r\n",
    "            #使用backward()方法可以执行反向网络\r\n",
    "            avg_loss.backward()\r\n",
    "            optimizer.minimize(avg_loss)\r\n",
    "             \r\n",
    "            #将参数梯度清零以保证下一轮训练的正确性\r\n",
    "            cnn.clear_gradients()\r\n",
    "            \r\n",
    "            dy_param_value = {}\r\n",
    "            for param in cnn.parameters():\r\n",
    "                dy_param_value[param.name] = param.numpy\r\n",
    "                \r\n",
    "            if batch_id % 10 == 0:\r\n",
    "                print(\"Loss at epoch {} step {}: {}\".format(epoch_num, batch_id, avg_loss.numpy()))\r\n",
    "    #保存模型参数\r\n",
    "    fluid.save_dygraph(cnn.state_dict(), \"cnn\")   \r\n",
    "    print(\"Final loss: {}\".format(avg_loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "结束\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\r\n",
    "\r\n",
    "'''\r\n",
    "模型预测\r\n",
    "'''\r\n",
    "with fluid.dygraph.guard():\r\n",
    "    model, _ = fluid.dygraph.load_dygraph(\"cnn\")\r\n",
    "    cnn = CNN()\r\n",
    "    cnn.load_dict(model)\r\n",
    "    cnn.eval()\r\n",
    "\r\n",
    "    #获取预测图片列表\r\n",
    "    test_zfile = zipfile.ZipFile(\"/home/aistudio/data/data1917/test_new.zip\")\r\n",
    "    l_test = []\r\n",
    "    for test_fname in test_zfile.namelist()[1:]:\r\n",
    "        \r\n",
    "        l_test.append(test_fname)\r\n",
    "   \r\n",
    "\r\n",
    "    for  index in range(len(l_test)):\r\n",
    "       \r\n",
    "        test_img = Image.open(l_test[index])\r\n",
    "        test_img = test_img.resize((640,480))\r\n",
    "        test_im = np.array(test_img)\r\n",
    "        test_im = test_im / 255.0\r\n",
    "        test_im = test_im.transpose().reshape(3,640,480).astype('float32')\r\n",
    "        l_test[index] = l_test[index].lstrip('test').lstrip('/')\r\n",
    "\r\n",
    "        dy_x_data = np.array(test_im).astype('float32')\r\n",
    "        dy_x_data=dy_x_data[np.newaxis,:, : ,:]\r\n",
    "        img = fluid.dygraph.to_variable(dy_x_data)\r\n",
    "        out = cnn(img)\r\n",
    "        temp=out[0][0]\r\n",
    "        temp=temp.numpy()\r\n",
    "        people =np.sum(temp)\r\n",
    "        data_dict[l_test[index]]=int(people)\r\n",
    "        \r\n",
    "import csv\r\n",
    "\r\n",
    "with open('results.csv', 'w') as csvfile:\r\n",
    "\r\n",
    "    fieldnames = ['id', 'predicted']\r\n",
    "\r\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\r\n",
    "\r\n",
    "    writer.writeheader()\r\n",
    "\r\n",
    "    for k,v in data_dict.items():\r\n",
    "\r\n",
    "        writer.writerow({'id': k, 'predicted':v})\r\n",
    "print(\"结束\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: [1.0431062e-06]\n"
     ]
    }
   ],
   "source": [
    "print(\"Final loss: {}\".format(avg_loss.numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.7.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
